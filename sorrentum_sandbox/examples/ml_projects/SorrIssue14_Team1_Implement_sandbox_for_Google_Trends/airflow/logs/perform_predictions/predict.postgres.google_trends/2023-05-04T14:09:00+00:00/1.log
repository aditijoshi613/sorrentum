[2023-05-04 14:13:01,755] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: perform_predictions.predict.postgres.google_trends scheduled__2023-05-04T14:09:00+00:00 [queued]>
[2023-05-04 14:13:01,764] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: perform_predictions.predict.postgres.google_trends scheduled__2023-05-04T14:09:00+00:00 [queued]>
[2023-05-04 14:13:01,765] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2023-05-04 14:13:01,766] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2023-05-04 14:13:01,767] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2023-05-04 14:13:01,778] {taskinstance.py:1262} INFO - Executing <Task(BashOperator): predict.postgres.google_trends> on 2023-05-04 14:09:00+00:00
[2023-05-04 14:13:01,782] {standard_task_runner.py:52} INFO - Started process 270 to run task
[2023-05-04 14:13:01,785] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'perform_predictions', 'predict.postgres.google_trends', 'scheduled__2023-05-04T14:09:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/***_predictions_scheduler.py', '--cfg-path', '/tmp/tmp0shjy38f', '--error-file', '/tmp/tmpbikh6k1a']
[2023-05-04 14:13:01,787] {standard_task_runner.py:77} INFO - Job 22: Subtask predict.postgres.google_trends
[2023-05-04 14:13:01,829] {logging_mixin.py:109} INFO - Running <TaskInstance: perform_predictions.predict.postgres.google_trends scheduled__2023-05-04T14:09:00+00:00 [running]> on host c896eb598e2f
[2023-05-04 14:13:01,874] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=perform_predictions
AIRFLOW_CTX_TASK_ID=predict.postgres.google_trends
AIRFLOW_CTX_EXECUTION_DATE=2023-05-04T14:09:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-05-04T14:09:00+00:00
[2023-05-04 14:13:01,876] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2023-05-04 14:13:01,877] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'sleep 5 && /cmamp/src/load_validate_transform.py --source_table google_trends_data --target_table google_trends_predictions --topic DSLR']
[2023-05-04 14:13:01,884] {subprocess.py:85} INFO - Output:
[2023-05-04 14:13:24,839] {subprocess.py:89} INFO -     Topic      Time  Frequency
[2023-05-04 14:13:24,840] {subprocess.py:89} INFO - 0    dslr  Jan 2004        7.0
[2023-05-04 14:13:24,841] {subprocess.py:89} INFO - 1    dslr  Feb 2004       10.0
[2023-05-04 14:13:24,842] {subprocess.py:89} INFO - 2    dslr  Mar 2004        6.0
[2023-05-04 14:13:24,843] {subprocess.py:89} INFO - 3    dslr  Apr 2004        6.0
[2023-05-04 14:13:24,844] {subprocess.py:89} INFO - 4    dslr  May 2004        7.0
[2023-05-04 14:13:24,845] {subprocess.py:89} INFO - ..    ...       ...        ...
[2023-05-04 14:13:24,846] {subprocess.py:89} INFO - 227  dslr  Dec 2022       30.0
[2023-05-04 14:13:24,847] {subprocess.py:89} INFO - 228  dslr  Jan 2023       31.0
[2023-05-04 14:13:24,848] {subprocess.py:89} INFO - 229  dslr  Feb 2023       31.0
[2023-05-04 14:13:24,849] {subprocess.py:89} INFO - 230  dslr  Mar 2023       30.0
[2023-05-04 14:13:24,850] {subprocess.py:89} INFO - 231  dslr  Apr 2023       28.0
[2023-05-04 14:13:24,850] {subprocess.py:89} INFO - 
[2023-05-04 14:13:24,851] {subprocess.py:89} INFO - [232 rows x 3 columns]
[2023-05-04 14:13:24,852] {subprocess.py:89} INFO - Running all QA checks:
[2023-05-04 14:13:24,853] {subprocess.py:89} INFO - DenormalizedDatasetCheck: PASSED
[2023-05-04 14:13:24,854] {subprocess.py:89} INFO - Step 1: Converting to Dask Dataframe, Done
[2023-05-04 14:13:24,855] {subprocess.py:89} INFO - Step 2: Preprocessing before prediction, Done
[2023-05-04 14:13:24,855] {subprocess.py:89} INFO - Performing stepwise search to minimize aic
[2023-05-04 14:13:24,856] {subprocess.py:89} INFO -  ARIMA(0,1,0)(0,1,0)[12]             : AIC=1232.807, Time=0.05 sec
[2023-05-04 14:13:24,857] {subprocess.py:89} INFO -  ARIMA(1,1,0)(1,1,0)[12]             : AIC=1182.616, Time=0.20 sec
[2023-05-04 14:13:24,859] {subprocess.py:89} INFO -  ARIMA(0,1,1)(0,1,1)[12]             : AIC=1177.405, Time=0.20 sec
[2023-05-04 14:13:24,860] {subprocess.py:89} INFO -  ARIMA(0,1,1)(0,1,0)[12]             : AIC=1210.067, Time=0.09 sec
[2023-05-04 14:13:24,861] {subprocess.py:89} INFO -  ARIMA(0,1,1)(1,1,1)[12]             : AIC=1178.835, Time=0.38 sec
[2023-05-04 14:13:24,861] {subprocess.py:89} INFO -  ARIMA(0,1,1)(0,1,2)[12]             : AIC=1178.865, Time=0.72 sec
[2023-05-04 14:13:24,862] {subprocess.py:89} INFO -  ARIMA(0,1,1)(1,1,0)[12]             : AIC=1179.245, Time=0.16 sec
[2023-05-04 14:13:24,863] {subprocess.py:89} INFO -  ARIMA(0,1,1)(1,1,2)[12]             : AIC=1180.826, Time=0.88 sec
[2023-05-04 14:13:24,864] {subprocess.py:89} INFO -  ARIMA(0,1,0)(0,1,1)[12]             : AIC=1195.630, Time=0.27 sec
[2023-05-04 14:13:24,865] {subprocess.py:89} INFO -  ARIMA(1,1,1)(0,1,1)[12]             : AIC=1179.220, Time=0.54 sec
[2023-05-04 14:13:24,866] {subprocess.py:89} INFO -  ARIMA(0,1,2)(0,1,1)[12]             : AIC=1179.184, Time=0.24 sec
[2023-05-04 14:13:24,867] {subprocess.py:89} INFO -  ARIMA(1,1,0)(0,1,1)[12]             : AIC=1180.869, Time=0.18 sec
[2023-05-04 14:13:24,867] {subprocess.py:89} INFO -  ARIMA(1,1,2)(0,1,1)[12]             : AIC=1175.514, Time=0.71 sec
[2023-05-04 14:13:24,868] {subprocess.py:89} INFO -  ARIMA(1,1,2)(0,1,0)[12]             : AIC=1213.807, Time=0.09 sec
[2023-05-04 14:13:24,869] {subprocess.py:89} INFO -  ARIMA(1,1,2)(1,1,1)[12]             : AIC=1176.695, Time=0.99 sec
[2023-05-04 14:13:24,870] {subprocess.py:89} INFO -  ARIMA(1,1,2)(0,1,2)[12]             : AIC=1176.652, Time=1.33 sec
[2023-05-04 14:13:24,871] {subprocess.py:89} INFO -  ARIMA(1,1,2)(1,1,0)[12]             : AIC=1176.647, Time=0.72 sec
[2023-05-04 14:13:24,872] {subprocess.py:89} INFO -  ARIMA(1,1,2)(1,1,2)[12]             : AIC=inf, Time=3.45 sec
[2023-05-04 14:13:24,873] {subprocess.py:89} INFO -  ARIMA(2,1,2)(0,1,1)[12]             : AIC=1177.435, Time=0.75 sec
[2023-05-04 14:13:24,874] {subprocess.py:89} INFO -  ARIMA(1,1,3)(0,1,1)[12]             : AIC=1182.298, Time=0.82 sec
[2023-05-04 14:13:24,875] {subprocess.py:89} INFO -  ARIMA(0,1,3)(0,1,1)[12]             : AIC=1181.019, Time=0.30 sec
[2023-05-04 14:13:24,876] {subprocess.py:89} INFO -  ARIMA(2,1,1)(0,1,1)[12]             : AIC=1181.032, Time=0.38 sec
[2023-05-04 14:13:24,877] {subprocess.py:89} INFO -  ARIMA(2,1,3)(0,1,1)[12]             : AIC=inf, Time=1.69 sec
[2023-05-04 14:13:24,877] {subprocess.py:89} INFO -  ARIMA(1,1,2)(0,1,1)[12] intercept   : AIC=1177.318, Time=0.61 sec
[2023-05-04 14:13:24,878] {subprocess.py:89} INFO - 
[2023-05-04 14:13:24,879] {subprocess.py:89} INFO - Best model:  ARIMA(1,1,2)(0,1,1)[12]
[2023-05-04 14:13:24,880] {subprocess.py:89} INFO - Total fit time: 15.767 seconds
[2023-05-04 14:13:24,881] {subprocess.py:89} INFO - Step 4: Predicting best fit using AIRMA models, Done
[2023-05-04 14:13:24,882] {subprocess.py:89} INFO - Step 5: Reformatting predictions according to DB requirements, Done
[2023-05-04 14:13:24,883] {subprocess.py:89} INFO - Step 6: Reformatting historical data according to DB requirements, Done
[2023-05-04 14:13:24,884] {subprocess.py:89} INFO - Step 7: Concatinating historical data with predictions, Done
[2023-05-04 14:13:24,885] {subprocess.py:89} INFO - Step 8: converting frequencies to 'int', Done
[2023-05-04 14:13:24,886] {subprocess.py:89} INFO - DELETE FROM google_trends_predictions WHERE topic = 'dslr'
[2023-05-04 14:13:25,072] {subprocess.py:93} INFO - Command exited with return code 0
[2023-05-04 14:13:25,099] {taskinstance.py:1280} INFO - Marking task as SUCCESS. dag_id=perform_predictions, task_id=predict.postgres.google_trends, execution_date=20230504T140900, start_date=20230504T141301, end_date=20230504T141325
[2023-05-04 14:13:25,122] {local_task_job.py:154} INFO - Task exited with return code 0
[2023-05-04 14:13:25,148] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
