{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import warnings\n",
    "from typing import Tuple, Any, Optional, List, Dict\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binance_futures = pd.read_parquet(r'C:\\Users\\James Zhang\\Desktop\\sorrentum\\sorrentum_sandbox\\projects\\SorrIssue2_Cross_exchange_arbitrage_CEX_CEX\\data\\Binance_futures')\n",
    "df_binance_futures = df_binance_futures.assign(exchange_id = 'binance_futures')\n",
    "df_binance_futures = df_binance_futures.rename(columns={'timestamp':'timestamp.1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binance_spot = pd.read_parquet(r'C:\\Users\\James Zhang\\Desktop\\sorrentum\\sorrentum_sandbox\\projects\\SorrIssue2_Cross_exchange_arbitrage_CEX_CEX\\data\\Binance_spot')\n",
    "df_binance_spot = df_binance_spot.assign(exchange_id = 'binance_spot')\n",
    "df_binance_spot = df_binance_spot.rename(columns={'timestamp':'timestamp.1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binance_us = pd.read_parquet(r'C:\\Users\\James Zhang\\Desktop\\sorrentum\\sorrentum_sandbox\\projects\\SorrIssue2_Cross_exchange_arbitrage_CEX_CEX\\data\\Binanceus_spot')\n",
    "df_binance_us = df_binance_us.rename(columns={'timestamp':'timestamp.1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_okx = pd.read_parquet(r'C:\\Users\\James Zhang\\Desktop\\sorrentum\\sorrentum_sandbox\\projects\\SorrIssue2_Cross_exchange_arbitrage_CEX_CEX\\data\\OKX_futures')\n",
    "df_okx = df_okx.rename(columns={'timestamp':'timestamp.1'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_multi_index(\n",
    "    exchange_df: pd.DataFrame,\n",
    "    keep_single: Optional[bool] = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rearrange the given exchange dataframe such that the index is time\n",
    "    and at any time, features of all coins on the exchange can be \n",
    "    determined.\n",
    "\n",
    "    :param exchange_df: data from some exchange\n",
    "    :return: nicer dataframe that will be input to define_levels\n",
    "    \"\"\"\n",
    "    # Move timestamp to a column and localize it.\n",
    "    exchange_df = exchange_df.reset_index()\n",
    "    exchange_df['timestamp'] = pd.to_datetime(exchange_df['timestamp'])\n",
    "    exchange_df['timestamp'] = exchange_df['timestamp'].dt.tz_localize(None)\n",
    "    exchange_df['timestamp'] = exchange_df['timestamp'].astype('datetime64[ns]')\n",
    "    exchange_df = exchange_df.sort_values(by='timestamp')\n",
    "    # Get the name of the exchange.\n",
    "    exchange_id = exchange_df['exchange_id'].unique()[0]\n",
    "    # Drop all irrelevant columns.\n",
    "    exchange_df = exchange_df.drop(columns=['timestamp.1', 'knowledge_timestamp', 'open', 'close', 'year', 'month', 'exchange_id'])\n",
    "    # Group the dataframe by currency pair.\n",
    "    currency_pair_dfs = exchange_df.groupby('currency_pair')\n",
    "    currency_pair_dfs = [currency_pair_dfs.get_group(currency_pair) for currency_pair in currency_pair_dfs.groups]\n",
    "    # Initialize the dataframe that we will return, which starts as just time.\n",
    "    return_df = pd.DataFrame(exchange_df['timestamp'].unique())\n",
    "    return_df = return_df.rename(columns={0:\"timestamp\"})\n",
    "    # Calls calculate_vwap helper function.\n",
    "    currency_pair_dfs = calculate_vwap(currency_pair_dfs, exchange_id) \n",
    "    # Merge all currency pair dataframes into the return dataframe\n",
    "    for currency_pair in currency_pair_dfs:\n",
    "        return_df = pd.merge_asof(return_df, currency_pair, on='timestamp')\n",
    "    # Set index as timestamp which was lost during merging.\n",
    "    return_df = return_df.set_index('timestamp')\n",
    "    # Sort by column name to the order is consistent.\n",
    "    reutrn_df = return_df.sort_index(axis=1)\n",
    "    # Drop duplicate columns if there are any\n",
    "    return_df = return_df.loc[:,~return_df.columns.duplicated()]\n",
    "    # Call define_levels function for next step.\n",
    "    if keep_single:\n",
    "        return return_df\n",
    "    return define_levels(return_df)\n",
    "\n",
    "def calculate_vwap(\n",
    "    currency_pair_dfs: List[pd.DataFrame],\n",
    "    exchange_id: str\n",
    ") -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates volume weighted average price for each currency pair dataframe\n",
    "    in the given list of currency pair dataframes.\n",
    "\n",
    "    :param currency_pair_dfs: list of currency pair dataframes\n",
    "    :param exchange_id: str name of the given exchange\n",
    "    :return: currency pair dataframes with vwap calculations\n",
    "    \"\"\"\n",
    "    for df in currency_pair_dfs:\n",
    "        # Get name of currency_pair for renaming purposes.\n",
    "        currency_pair = df[\"currency_pair\"].unique()[0]\n",
    "        vwap_column_name = f\"vwap-{exchange_id}:{currency_pair}\"\n",
    "        volume_column_name = f\"volume-{exchange_id}:{currency_pair}\"\n",
    "        # Calculate vwap.\n",
    "        midprice = (df[\"high\"] + df[\"low\"]) / 2\n",
    "        numerator = np.cumsum(np.multiply(df[\"volume\"], midprice))\n",
    "        denominator = np.cumsum(df[\"volume\"])\n",
    "        df[vwap_column_name] = np.divide(numerator, denominator)\n",
    "        # Now rename the volume column.\n",
    "        df.rename(columns={'volume' : volume_column_name}, inplace=True)\n",
    "        # Drop irrelevant columns and set timestamp as index.\n",
    "        df.drop(columns=['high', 'low', 'currency_pair'], inplace=True)\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "    return currency_pair_dfs\n",
    "\n",
    "def define_levels(single_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create all of the column levels such that we can transform \n",
    "    the single_index_df into multi_index.\n",
    "    \n",
    "    :param single_df: dataframe returned by convert_to_multi_index\n",
    "    :return: a multi-index dataframe\n",
    "    \"\"\"\n",
    "    # Store the timestamp for later use.\n",
    "    timestamp = single_df.index\n",
    "    # Create a list of all column names.\n",
    "    columns = list(single_df.columns)\n",
    "    # Create outer level (feature).\n",
    "    volume_string = \"volume \" * int(len(columns) / 2)\n",
    "    vwap_string = \"vwap \" * int(len(columns) / 2)\n",
    "    feature_string = \"\".join([volume_string, vwap_string])\n",
    "    # Simultaneously create middle level (exchange) and inner level (currency pairs)\n",
    "    exchange_string = \"\"\n",
    "    currency_pair_string = \"\"\n",
    "    for column_name in columns:\n",
    "        hyphen = column_name.rfind(\"-\")\n",
    "        semicolon = column_name.rfind(\":\")\n",
    "        exchange_string += column_name[hyphen + 1:semicolon] + \" \"\n",
    "        currency_pair_string += column_name[semicolon + 1:] + \" \"\n",
    "    # Convert the given dataframe to multi-index\n",
    "    return_df = pd.DataFrame(np.array(single_df), columns=[feature_string.split(), exchange_string.split(), currency_pair_string.split()])\n",
    "    # Restore the initial timestamp\n",
    "    return_df.index = timestamp\n",
    "    # Drop duplicate columns if there are any\n",
    "    return_df = return_df.loc[:,~return_df.columns.duplicated()].copy()\n",
    "    return return_df\n",
    "\n",
    "def merge_and_convert_to_multi_index(\n",
    "    exchange_dfs: List[pd.DataFrame]\n",
    ") -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Converts a list of exchange dataframes into one large\n",
    "    multi-index dataframe.\n",
    "\n",
    "    :param exchange_dfs: list of all exchange dataframes\n",
    "    :return: multi-index dataframe\n",
    "    \"\"\"\n",
    "    # Edge case if exchange_dfs of size == 1\n",
    "    if len(exchange_dfs) == 1:\n",
    "        return convert_to_multi_index(exchange_df)\n",
    "    # Make all dataframes in exchange_dfs easily convertible to multi-index\n",
    "    for i, exchange_df in enumerate(exchange_dfs):\n",
    "        exchange_dfs[i] = convert_to_multi_index(exchange_df, True)\n",
    "    # Merge the first two dataframes\n",
    "    return_df = pd.merge(exchange_dfs[0], exchange_dfs[1], on=\"timestamp\", how=\"outer\")\n",
    "    # Now merge the rest of them\n",
    "    for i in range(2, len(exchange_dfs)):\n",
    "        return_df = pd.merge(return_df, exchange_dfs[i], on=\"timestamp\", how=\"outer\")\n",
    "    # Sort by time and columns before passing into define_levels\n",
    "    return_df = return_df.sort_index()\n",
    "    return_df = return_df.sort_index(axis=1)\n",
    "    # Drop duplicate columns if there are any\n",
    "    return_df = return_df.loc[:,~return_df.columns.duplicated()]\n",
    "    return define_levels(return_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">volume</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">binance_futures</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">okx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>APE_USDT</th>\n",
       "      <th>AVAX_USDT</th>\n",
       "      <th>AXS_USDT</th>\n",
       "      <th>BAKE_USDT</th>\n",
       "      <th>BNB_USDT</th>\n",
       "      <th>BTC_BUSD</th>\n",
       "      <th>BTC_USDT</th>\n",
       "      <th>CRV_USDT</th>\n",
       "      <th>CTK_USDT</th>\n",
       "      <th>DOGE_USDT</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM_USDT</th>\n",
       "      <th>GMT_USDT</th>\n",
       "      <th>LINK_USDT</th>\n",
       "      <th>MATIC_USDT</th>\n",
       "      <th>NEAR_USDT</th>\n",
       "      <th>SAND_USDT</th>\n",
       "      <th>SOL_USDT</th>\n",
       "      <th>STORJ_USDT</th>\n",
       "      <th>WAVES_USDT</th>\n",
       "      <th>XRP_USDT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-08 17:57:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-08 17:58:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-08 17:59:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-08 18:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-08 18:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:55:00</th>\n",
       "      <td>14535.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>357.12</td>\n",
       "      <td>74.177</td>\n",
       "      <td>276.408</td>\n",
       "      <td>141575.9</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>6800853.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:56:00</th>\n",
       "      <td>13328.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>12681.0</td>\n",
       "      <td>23143.0</td>\n",
       "      <td>301.87</td>\n",
       "      <td>36.406</td>\n",
       "      <td>198.219</td>\n",
       "      <td>145940.2</td>\n",
       "      <td>4929.0</td>\n",
       "      <td>4902330.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:57:00</th>\n",
       "      <td>10989.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>13094.0</td>\n",
       "      <td>403.85</td>\n",
       "      <td>14.833</td>\n",
       "      <td>149.375</td>\n",
       "      <td>101247.9</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>6779943.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:58:00</th>\n",
       "      <td>15542.0</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>5678.0</td>\n",
       "      <td>25428.0</td>\n",
       "      <td>181.45</td>\n",
       "      <td>34.365</td>\n",
       "      <td>130.329</td>\n",
       "      <td>8523.5</td>\n",
       "      <td>10357.0</td>\n",
       "      <td>3246096.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:59:00</th>\n",
       "      <td>9623.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>11387.0</td>\n",
       "      <td>4790.0</td>\n",
       "      <td>277.87</td>\n",
       "      <td>19.810</td>\n",
       "      <td>150.422</td>\n",
       "      <td>27284.0</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>6019292.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1787402 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             volume                                         \n",
       "                    binance_futures                                         \n",
       "                           APE_USDT AVAX_USDT AXS_USDT BAKE_USDT BNB_USDT   \n",
       "timestamp                                                                   \n",
       "2019-09-08 17:57:00             NaN       NaN      NaN       NaN      NaN  \\\n",
       "2019-09-08 17:58:00             NaN       NaN      NaN       NaN      NaN   \n",
       "2019-09-08 17:59:00             NaN       NaN      NaN       NaN      NaN   \n",
       "2019-09-08 18:00:00             NaN       NaN      NaN       NaN      NaN   \n",
       "2019-09-08 18:01:00             NaN       NaN      NaN       NaN      NaN   \n",
       "...                             ...       ...      ...       ...      ...   \n",
       "2023-01-31 23:55:00         14535.0    4127.0   3298.0    3810.0   357.12   \n",
       "2023-01-31 23:56:00         13328.0    3890.0  12681.0   23143.0   301.87   \n",
       "2023-01-31 23:57:00         10989.0    5453.0   2843.0   13094.0   403.85   \n",
       "2023-01-31 23:58:00         15542.0    1896.0   5678.0   25428.0   181.45   \n",
       "2023-01-31 23:59:00          9623.0    1594.0  11387.0    4790.0   277.87   \n",
       "\n",
       "                                                                     ...   \n",
       "                                                                     ...   \n",
       "                    BTC_BUSD BTC_USDT  CRV_USDT CTK_USDT  DOGE_USDT  ...   \n",
       "timestamp                                                            ...   \n",
       "2019-09-08 17:57:00      NaN    0.001       NaN      NaN        NaN  ...  \\\n",
       "2019-09-08 17:58:00      NaN    0.000       NaN      NaN        NaN  ...   \n",
       "2019-09-08 17:59:00      NaN    0.001       NaN      NaN        NaN  ...   \n",
       "2019-09-08 18:00:00      NaN    0.000       NaN      NaN        NaN  ...   \n",
       "2019-09-08 18:01:00      NaN    0.000       NaN      NaN        NaN  ...   \n",
       "...                      ...      ...       ...      ...        ...  ...   \n",
       "2023-01-31 23:55:00   74.177  276.408  141575.9   5638.0  6800853.0  ...   \n",
       "2023-01-31 23:56:00   36.406  198.219  145940.2   4929.0  4902330.0  ...   \n",
       "2023-01-31 23:57:00   14.833  149.375  101247.9   4621.0  6779943.0  ...   \n",
       "2023-01-31 23:58:00   34.365  130.329    8523.5  10357.0  3246096.0  ...   \n",
       "2023-01-31 23:59:00   19.810  150.422   27284.0   9713.0  6019292.0  ...   \n",
       "\n",
       "                        vwap                                           \n",
       "                         okx                                           \n",
       "                    FTM_USDT GMT_USDT LINK_USDT MATIC_USDT NEAR_USDT   \n",
       "timestamp                                                              \n",
       "2019-09-08 17:57:00      NaN      NaN       NaN        NaN       NaN  \\\n",
       "2019-09-08 17:58:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2019-09-08 17:59:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2019-09-08 18:00:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2019-09-08 18:01:00      NaN      NaN       NaN        NaN       NaN   \n",
       "...                      ...      ...       ...        ...       ...   \n",
       "2023-01-31 23:55:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2023-01-31 23:56:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2023-01-31 23:57:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2023-01-31 23:58:00      NaN      NaN       NaN        NaN       NaN   \n",
       "2023-01-31 23:59:00      NaN      NaN       NaN        NaN       NaN   \n",
       "\n",
       "                                                                       \n",
       "                                                                       \n",
       "                    SAND_USDT SOL_USDT STORJ_USDT WAVES_USDT XRP_USDT  \n",
       "timestamp                                                              \n",
       "2019-09-08 17:57:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2019-09-08 17:58:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2019-09-08 17:59:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2019-09-08 18:00:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2019-09-08 18:01:00       NaN      NaN        NaN        NaN      NaN  \n",
       "...                       ...      ...        ...        ...      ...  \n",
       "2023-01-31 23:55:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2023-01-31 23:56:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2023-01-31 23:57:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2023-01-31 23:58:00       NaN      NaN        NaN        NaN      NaN  \n",
       "2023-01-31 23:59:00       NaN      NaN        NaN        NaN      NaN  \n",
       "\n",
       "[1787402 rows x 198 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merge_and_convert_to_multi_index([df_binance_futures, df_binance_spot, df_binance_spot, df_okx])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8437d981fa64f2a1beb3461e7d14621165f4ab9e79bbc405a2415a011cad668"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
